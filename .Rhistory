m <- train(admit~., data=trainset, method="svmLinear",
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
m    #check model details
m    #check model details
#predict
pred <- predict(m, testset)
#Definition of label column vector & Labeldata
actual_type <- testset$admit
predict_type <- pred
positive_val <- "Y"
negative_val <- "N"
#1) Accuracy
tab <- table(Predicted=pred, Actual=testset$admit)
tab
sum(diag(tab)) / sum(tab)    #testset_Accuracy
###Caret Packages -- train()
##0.1 Load data
binary <- read.csv("binary.csv")
binary$admit <- factor( binary$admit, labels=c("Y", "N"))
str(binary)
set.seed(5311)
library(caret)
k <- createDataPartition(binary$admit, p=0.80, list=F)
trainset <- binary[k, ]
testset <- binary[-k, ]
nrow(trainset)    #321
nrow(testset)    #79
##3. svmPoly ---------------------------------------------
#install.packages("kernlab")
library(kernlab)
ctrl <- trainControl(method="cv", number=10,  # k-hold 교차검정하겠다.
selectionFunction="oneSE")
grid <- expand.grid(C=c(1,2,3,4,5))  # 하이퍼파라미터 C 를 지정
m <- train(admit~., data=trainset, method="svmPoly",
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
m    #check model details
#Definition of label column vector & Labeldata
actual_type <- testset$admit
predict_type <- pred
positive_val <- "Y"
negative_val <- "N"
tab
sum(diag(tab)) / sum(tab)    #testset_Accuracy
table( actual_type, predict_type)
Kappa( table( actual_type, predict_type)  )
#predict
pred <- predict(m, testset)
#1) Accuracy
tab <- table(Predicted=pred, Actual=testset$admit)
#2) Kappa statistics
#install.packages("vcd")
library(vcd)
#2) Kappa statistics
install.packages("vcd")
install.packages("vcd")
library(vcd)
table( actual_type, predict_type)
Kappa( table( actual_type, predict_type)  )
#Definition of label column vector & Labeldata
actual_type <- testset$admit
predict_type <- pred
positive_val <- "Y"
negative_val <- "N"
#1) Accuracy
tab <- table(Predicted=pred, Actual=testset$admit)
tab
sum(diag(tab)) / sum(tab)    #testset_Accuracy
m <- train(admit~., data=trainset, method="polynominal ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
set.seed(5311) #시드값변경
library(caret)
k <- createDataPartition(binary$admit, p=0.80, list=F)
trainset <- binary[k, ]
testset <- binary[-k, ]
nrow(trainset)    #321
nrow(testset)    #79
##3. svmPoly ---------------------------------------------
#install.packages("kernlab")
library(kernlab)
ctrl <- trainControl(method="cv", number=10,  # k-hold 교차검정하겠다.
selectionFunction="oneSE")
grid <- expand.grid(C=c(1,2,3,4,5))  # 하이퍼파라미터 C 를 지정
m <- train(admit~., data=trainset, method="polynominal ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
m <- train(admit~., data=trainset, method="sigmoid ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
m <- train(admit~., data=trainset, method="polynomial ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
grid <- expand.grid(C=c(1,2,3,4,5))  # 하이퍼파라미터 C 를 지정
polynomial(1:4)
polynomial(coef = c(0, 1))
m <- train(admit~., data=trainset, method="svmPoly  ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
ctrl <- trainControl(method="cv", number=10,  # k-hold 교차검정하겠다.
selectionFunction="oneSE")
grid <- expand.grid(C=c(1,2,3,4,5))  # 하이퍼파라미터 C 를 지정
m <- train(admit~., data=trainset, method="svmPoly  ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
library(caret)
ctrl <- trainControl(method="cv", number=10,  # k-hold 교차검정하겠다.
selectionFunction="oneSE")
grid <- expand.grid(C=c(1,2,3,4,5))  # 하이퍼파라미터 C 를 지정
m <- train(admit~., data=trainset, method="svmPoly  ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
##3. svmPoly ---------------------------------------------
#install.packages("kernlab")
library(kernlab)
ctrl <- trainControl(method="cv", number=10,  # k-hold 교차검정하겠다.
selectionFunction="oneSE")
grid <- expand.grid(C=c(1,2,3,4,5))  # 하이퍼파라미터 C 를 지정
m <- train(admit~., data=trainset, method="svmPoly  ", #비선형
metric="Accuracy",
trControl=ctrl,
tunegrid=grid)
m <- train(admit~., data=trainset, method="svmPoly",
metric="Accuracy",
trControl=ctrl,
tunegrid=grid) #비선형
library(ggplot2)
library(lattice)
library(kernlab)
library(caret)
library(doParallel)
# Enable parallel processing.
cl <- makeCluster(detectCores()) #코어의 갯수만큼 병렬처리
#install.packages("caret")
install.packages("doParallel") #병렬처리하는 패키지(데이터양이 많아서)
library(ggplot2)
library(lattice)
library(kernlab)
library(caret)
library(doParallel)
# Enable parallel processing.
cl <- makeCluster(detectCores()) #코어의 갯수만큼 병렬처리
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
# Load the MNIST digit recognition dataset into R
# http://yann.lecun.com/exdb/mnist/
# assume you have all 4 files and gunzip'd them
# creates train$n, train$x, train$y  and test$n, test$x, test$y
# e.g. train$x is a 60000 x 784 matrix, each row is one digit (28x28)
# call:  show_digit(train$x[5,])   to see a digit.
# brendan o'connor - gist.github.com/39760 - anyall.org
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
#실제 코드 진행 시작
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
# Load the MNIST digit recognition dataset into R
# http://yann.lecun.com/exdb/mnist/
# assume you have all 4 files and gunzip'd them
# creates train$n, train$x, train$y  and test$n, test$x, test$y
# e.g. train$x is a 60000 x 784 matrix, each row is one digit (28x28)
# call:  show_digit(train$x[5,])   to see a digit.
# brendan o'connor - gist.github.com/39760 - anyall.org
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
# brendan o'connor - gist.github.com/39760 - anyall.org
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
# Load data.
load_mnist()
library(ggplot2)
library(lattice)
library(kernlab)
library(caret)
library(doParallel)
# Enable parallel processing.
cl <- makeCluster(detectCores()) #코어의 갯수만큼 병렬처리
cl
registerDoParallel(cl)
# Load the MNIST digit recognition dataset into R
# http://yann.lecun.com/exdb/mnist/
# assume you have all 4 files and gunzip'd them
# creates train$n, train$x, train$y  and test$n, test$x, test$y
# e.g. train$x is a 60000 x 784 matrix, each row is one digit (28x28)
# call:  show_digit(train$x[5,])   to see a digit.
# brendan o'connor - gist.github.com/39760 - anyall.org
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
# Enable parallel processing.
cl <- makeCluster(detectCores()) #코어의 갯수만큼 병렬처리
cl
library(ggplot2)
library(gmodels)
library(ggplot2)
library(lattice)
library(kernlab)
library(caret)
library(doParallel)
# Enable parallel processing.
cl <- makeCluster(detectCores()) #코어의 갯수만큼 병렬처리
cl
train <- data.frame()
test <- data.frame()
# Load the MNIST digit recognition dataset into R
# http://yann.lecun.com/exdb/mnist/
# assume you have all 4 files and gunzip'd them
# creates train$n, train$x, train$y  and test$n, test$x, test$y
# e.g. train$x is a 60000 x 784 matrix, each row is one digit (28x28)
# call:  show_digit(train$x[5,])   to see a digit.
# brendan o'connor - gist.github.com/39760 - anyall.org
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
str(train)
#mnist 다운받는 코드
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
str(train)
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
str(train)
setwd("/Users/macbook/Documents/itwill/R")
# Enable parallel processing.
cl <- makeCluster(detectCores()) #코어의 갯수만큼 병렬처리
cl
registerDoParallel(cl)
show_digit <- function(arr784, col=gray(12:1/12), ...) {
image(matrix(arr784, nrow=28)[,28:1], col=col, ...)
}
train <- data.frame()
test <- data.frame()
str(train)
train$x <- train$x / 255
inTrain = data.frame(y=train$y, train$x)
inTrain$y <- as.factor(inTrain$y)
trainIndex = createDataPartition(inTrain$y, p = 0.60,list=FALSE)
training = inTrain[trainIndex,]
cv = inTrain[-trainIndex,]
fit <- train(y ~ ., data = head(training, 1000), method = 'svmRadial', tuneGrid = data.frame(sigma=0.0107249, C=1))
results <- predict(fit, newdata = head(cv, 1000))
results
confusionMatrix(results, head(cv$y, 1000))
show_digit(as.matrix(training[5,2:785]))
# Check the actual answer for the digit.
training[5,1]
load_mnist <- function() {
load_image_file <- function(filename) {
ret = list()
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
ret$n = readBin(f,'integer',n=1,size=4,endian='big')
nrow = readBin(f,'integer',n=1,size=4,endian='big')
ncol = readBin(f,'integer',n=1,size=4,endian='big')
x = readBin(f,'integer',n=ret$n*nrow*ncol,size=1,signed=F)
ret$x = matrix(x, ncol=nrow*ncol, byrow=T)
close(f)
ret
}
load_label_file <- function(filename) {
f = file(filename,'rb')
readBin(f,'integer',n=1,size=4,endian='big')
n = readBin(f,'integer',n=1,size=4,endian='big')
y = readBin(f,'integer',n=n,size=1,signed=F)
close(f)
y
}
train <<- load_image_file('train-images.idx3-ubyte')
test <<- load_image_file('t10k-images.idx3-ubyte')
train$y <<- load_label_file('train-labels.idx1-ubyte')
test$y <<- load_label_file('t10k-labels.idx1-ubyte')
}
# Load data.
load_mnist()
# Predict the digit.
predict(fit, newdata = training[5,])
#install.packages("caret")
#install.packages("doParallel") #병렬처리하는 패키지(데이터양이 많아서)
install.packages("kernlab")
install.packages("kernlab")
#install.packages("ggplot2")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
library(ggplot2)
library(lattice)
#install.packages("ggplot2")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
