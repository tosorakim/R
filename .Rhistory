sample(c(1:10), size=9, replace=TRUE)
set.seed(1)
sample(c(1:10), size=9, replace=FALSE)
sample(c(1:10), size=10, replace=FALSE)
sample(c(1:10), size=11, replace=FALSE)
set.seed(1)
sample(c(1:10), size=11, replace=TRUE)
set.seed(11)
sample( c(1,2), nrow(iris), replace=TRUE )
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
table(ind)
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
table(ind)
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
table(ind)
set.seed(11)
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
table(ind)
set.seed(11)
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
table(ind)
set.seed(11)
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
table(ind)
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
prop.table(table(ind))
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
prop.table(table(ind))
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
prop.table(table(ind))
ind <- sample( c(1,2), 150, replace=TRUE, prob=c(0.7, 0.3) )
ind==1
sum(ind==1)
sum(ind==1)
sum(ind==1)
iris[ ind==1, ]
nrow(iris[ ind==1, ])
nrow(iris[ ind==1, ])
iris[ ind==2, ]
nrow(iris[ ind==2, ])
head(iris)
iris[ iris$Sepal.Length >= 5.0, ]
iris$Sepal.Length >= 5.0
setwd("/Users/macbook/Documents/itwill/R")
wine <- read.csv("wine.csv", header = TRUE,  stringsAsFactors = T)
View(wine)
wine
head(wine)
nrow(wine) #178
ncol(wine) #14
table(wine$Type)
View(wine)
plot(wine_ctree)
#결오빠: 정확도 확인 추가
result <- predict(wine_ctree,testData[,-1])
g2 <- CrossTable(result,testData$Type)
sum(g2$prop.tbl*diag(3))
g2 <- CrossTable(testData$Type, result)
sum(g2$prop.tbl*diag(3))
plot(wine_ctree)
credit <- credit.csv("wine.csv", header = TRUE,  stringsAsFactors = T)
setwd("/Users/macbook/Documents/itwill/R")
credit <- credit.csv("wine.csv", header = TRUE,  stringsAsFactors = T)
credit <- red.csv("credit.csv", header = TRUE,  stringsAsFactors = T)
setwd("/Users/macbook/Documents/itwill/R")
credit <- red.csv("credit.csv", header = TRUE,  stringsAsFactors = T)
credit <- read.csv("credit.csv", header = TRUE,  stringsAsFactors = T)
str(credit)
prop.table(table(credit$default)
table(credit$default
table(credit$default)
prop.table(table(credit$default))
summary(credit$amount)
set.seed(123)
credit_shuffle <- credit[ sample(nrow(credit)), ]
nrow(credit_shffle) #1000
nrow(credit_shuffle) #1000
nrow(credit)
train_num <- 0.9*1000
credit_train <- credit_suffle[ 1:train_num, ]
credit_train <- credit_shuffle[ 1:train_num, ]
credit_test <- credit_shuffle[ train_num+1 : nrow(credit_shuffle), ]
nrow(credit_train)
nrow(credit_test)
credit_test <- credit_shuffle[ (train_num+1) : nrow(credit_shuffle), ]
nrow(credit_train) #900
nrow(credit_test) #1000
library(C50)
str(credit_train)
ncol(credit_train)
credit_model <- C5.0( credit_train[ ,-17], credit_train$default)
credit_model
credit_result <- predict( credit_model, credit_test[ , -17])
credit_result
table(credit_result)
table(credit_test[  , 17])
table(credit_result, credit_test[  , 17])
library(gmodels)
CrossTable(x=credit_test[ ,17], y=credit_result)
table(credit_test[  , 17], credit_result)
CrossTable(x=credit_test[ ,17], y=credit_result)
print(x$prop.tbl*diag(2))
print(sum(x$prop.tbl*diag(2)))
diag(2)
print(sum(x$prop.tbl*diag(2)))
credit_model2 <- C5.0( credit_train[ , -17], credit_train$default, trials=100 )
#예측 다시 세우고
credit_result2 <- predict( credit_model2, credit_test[ , -17])
x <- CrossTable(x=credit_test[ ,17], y=credit_result)
print(sum(x$prop.tbl*diag(2)))
#모델 다시 세우고
credit_model2 <- C5.0( credit_train[ , -17], credit_train$default, trials=100 )
#예측 다시 세우고
credit_result2 <- predict( credit_model2, credit_test[ , -17])
#정확도 확인
x <- CrossTable(x=credit_test[ ,17], y=credit_result)
print(sum(x$prop.tbl*diag(2)))
credit <- read.csv("credit.csv", header = TRUE,  stringsAsFactors = T)
library(party)
library(gmodels)
setwd("/Users/macbook/Documents/itwill/R")
credit <- read.csv("credit.csv", header = TRUE,  stringsAsFactors = T)
View(credit)
str(credit)
colSums(is.na(credit))
table(credit$default)
set.seed(659) #최적의 seed값
#set.seed(123)
credit_shuffle <-  credit[ sample(1000),  ]
nrow(credit_shuffle)
#6. 데이터를 9대 1로 나눕니다. (훈련 데이터: 9, 테스트 데이터 : 1 )
train_num <-   0.9 * 1000
credit_train <- credit_shuffle[ 1:train_num,   ] #1번부터 900번째행까지
credit_test  <- credit_shuffle[ (train_num+1) : nrow(credit_shuffle),   ]
#  901번부터 1000번까지는 테스트 데이터로 구성
nrow(credit_train)  #900
nrow(credit_test)   #100
# 7. 의사결정트리 모델을 생성(party 패키지의 ctree함수 이용)
myformula <- default ~ .
credit_ctree <- ctree(myformula, data=credit_train)
predict(credit_ctree)
nrow(predict(credit_ctree))
length(predict(credit_ctree))
table(predict(credit_ctree), credit_train$default)
test_pred <- predict(credit_ctree, newdata=credit_test)
table(test_pred, credit_test$default)
plot(credit_ctree, type='simple')
plot(credit_ctree)
plot(credit_ctree, type='simple')
library(party)
#2.wine을 데이터를 불러온다.
c <-read.csv('credit.csv',stringsAsFactors=T)
c(head)
head(c)
summary(c)
View(c)
i<-1 #파이썬으로 치면 cnt = 1
#3.와인 데이터 라벨 컬럼 종류와 건수를 확인합니다.
summary(c$default)
i<-1 #파이썬으로 치면 cnt = 1
#repeat 는 루프문을 여는 건데, break 만날 때까지 계속 반복하겠다 라는 뜻
repeat{
set.seed(i)
i <- i+1 #i에 계속 i+1 넣으면서 반복
ind<-sample(2,nrow(c),replace=T,prob=c(0.7,0.3))
#5.ind==1과 ind==2를 이용해서 훈련데이터와 테스트 데이터를 만든다.
traindata <- c[ind==1,] #70%의 데이터로 훈련데이터
testdata <- c[ind==2,] #30%의 데이터로 테스트데이터
#6.의사결정트리 모델(나무)를 생성한다.
myformula <- Type ~ .
#7. party패키지의 ctree함수를 이용해서 의사결정모델을 생성한다.
c_ctree <- ctree(myformula,data=traindata)
#8.예측결과를 확인한다.
predict(c_ctree)
#9.예측결과와 실제 테스트 데이터의 정답과 비교한다.
table(predict(c_ctree),traindata$default)
#12.test데이터를 예측하고 확인한다.
testpred <- predict(wine_ctree, newdata=testdata)
library(gmodels)
g3<-CrossTable(testdata$Type, testpred)
x<- (g3$prop.tb[1] + g3$prop.tb[5]+g3$prop.tb[9]) 
if(x==1) break #정확도개 100이면 멈춰라
print(i) }
#repeat 는 루프문을 여는 건데, break 만날 때까지 계속 반복하겠다 라는 뜻
#repeat{
set.seed(i)
i <- i+1 #i에 계속 i+1 넣으면서 반복
ind<-sample(2,nrow(c),replace=T,prob=c(0.7,0.3))
ind
ind==1
ind==2
#5.ind==1과 ind==2를 이용해서 훈련데이터와 테스트 데이터를 만든다.
traindata <- c[ind==1,] #70%의 데이터로 훈련데이터
testdata <- c[ind==2,] #30%의 데이터로 테스트데이터
#6.의사결정트리 모델(나무)를 생성한다.
myformula <- Type ~ .
#7. party패키지의 ctree함수를 이용해서 의사결정모델을 생성한다.
c_ctree <- ctree(myformula,data=traindata)
#6.의사결정트리 모델(나무)를 생성한다.
myformula <- default ~ .
#7. party패키지의 ctree함수를 이용해서 의사결정모델을 생성한다.
c_ctree <- ctree(myformula,data=traindata)
#8.예측결과를 확인한다.
predict(c_ctree)
#9.예측결과와 실제 테스트 데이터의 정답과 비교한다.
table(predict(c_ctree),traindata$default)
#12.test데이터를 예측하고 확인한다.
testpred <- predict(c_ctree, newdata=testdata)
testpred
library(gmodels)
g3<-CrossTable(testdata$default, testpred)
x<- (g3$prop.tb[1] + g3$prop.tb[5]+g3$prop.tb[9]) 
if(x==1) break #정확도개 100이면 멈춰라
print(i) }
#repeat 는 루프문을 여는 건데, break 만날 때까지 계속 반복하겠다 라는 뜻
repeat{
set.seed(i)
i <- i+1 #i에 계속 i+1 넣으면서 반복
ind<-sample(2,nrow(c),replace=T,prob=c(0.7,0.3))
ind==1
#5.ind==1과 ind==2를 이용해서 훈련데이터와 테스트 데이터를 만든다.
traindata <- c[ind==1,] #70%의 데이터로 훈련데이터
testdata <- c[ind==2,] #30%의 데이터로 테스트데이터
#6.의사결정트리 모델(나무)를 생성한다.
myformula <- default ~ .
#7. party패키지의 ctree함수를 이용해서 의사결정모델을 생성한다.
c_ctree <- ctree(myformula,data=traindata)
#8.예측결과를 확인한다.
predict(c_ctree)
#9.예측결과와 실제 테스트 데이터의 정답과 비교한다.
table(predict(c_ctree),traindata$default)
#12.test데이터를 예측하고 확인한다.
testpred <- predict(c_ctree, newdata=testdata)
library(gmodels)
g3<-CrossTable(testdata$default, testpred)
x<- (g3$prop.tb[1] + g3$prop.tb[5]+g3$prop.tb[9]) 
if(x==1) break #정확도개 100이면 멈춰라
print(i) }
print(i) #seed가 1717일때 정확도 100%
#repeat 는 루프문을 여는 건데, break 만날 때까지 계속 반복하겠다 라는 뜻
repeat{
set.seed(i)
i <- i+1 #i에 계속 i+1 넣으면서 반복
ind<-sample(2,nrow(c),replace=T,prob=c(0.7,0.3))
ind==1
#5.ind==1과 ind==2를 이용해서 훈련데이터와 테스트 데이터를 만든다.
traindata <- c[ind==1,] #70%의 데이터로 훈련데이터
testdata <- c[ind==2,] #30%의 데이터로 테스트데이터
#6.의사결정트리 모델(나무)를 생성한다.
myformula <- default ~ .
#7. party패키지의 ctree함수를 이용해서 의사결정모델을 생성한다.
c_ctree <- ctree(myformula,data=traindata)
#8.예측결과를 확인한다.
predict(c_ctree)
#9.예측결과와 실제 테스트 데이터의 정답과 비교한다.
table(predict(c_ctree),traindata$default)
#12.test데이터를 예측하고 확인한다.
testpred <- predict(c_ctree, newdata=testdata)
library(gmodels)
g3<-CrossTable(testdata$default, testpred)
x<- (g3$prop.tb[1] + g3$prop.tb[5]+g3$prop.tb[9]) 
if(x==1) break #정확도개 100이면 멈춰라
print(i)
}
str(c)
nrow(c)
colSums(is.na(c))
table(c$default)
#9.예측결과와 실제 테스트 데이터의 정답과 비교한다.
table(predict(c_ctree),traindata$default)
ind==1
library(party)
c <-read.csv('credit.csv',stringsAsFactors=T)
View(c)
summary(c)
str(c) #type 확인 필수
nrow(c)
summary(c$default)
colSums(is.na(c))
table(c$default)
#repeat문 돌려서 seed값 찾기
i<-1 #파이썬으로 치면 cnt = 1
#repeat 는 루프문을 여는 건데, break 만날 때까지 계속 반복하겠다 라는 뜻
repeat{
set.seed(i)
i <- i+1 #i에 계속 i+1 넣으면서 반복
ind<-sample(2,nrow(c),replace=T,prob=c(0.9,0.1))
ind==1
#5.ind==1과 ind==2를 이용해서 훈련데이터와 테스트 데이터를 만든다.
traindata <- c[ind==1,] #70%의 데이터로 훈련데이터
testdata <- c[ind==2,] #30%의 데이터로 테스트데이터
#6.의사결정트리 모델(나무)를 생성한다.
myformula <- default ~ .
#7. party패키지의 ctree함수를 이용해서 의사결정모델을 생성한다.
c_ctree <- ctree(myformula,data=traindata)
#8.예측결과를 확인한다.
predict(c_ctree)
#9.예측결과와 실제 테스트 데이터의 정답과 비교한다.
table(predict(c_ctree),traindata$default)
#12.test데이터를 예측하고 확인한다.
testpred <- predict(c_ctree, newdata=testdata)
library(gmodels)
g3<-CrossTable(testdata$default, testpred)
x<- (g3$prop.tb[1] + g3$prop.tb[5]+g3$prop.tb[9]) 
if(x==1) break #정확도개 100이면 멈춰라
print(i)
}
print(i) #정확도
nrow(c)
install.packages("party")
library(party)
setwd("c:\\data")
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit)
nrow(credit)
summary(credit)
colSums(is.na(credit))
table(credit$default)
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
table(predict(credit_ctree),train_data$default)
testpred <- predict(credit_ctree, newdata=test_data)
table(testpred, test_data$default)
library(gmodels)
g2 <- CrossTable(test_data$default, testpred)
x <- sum(g2$prop.tbl*diag(2))
if(x>=0.86) break
print(i)}
print(i) # 393
x # 0.86
install.packages("party")
library(party)
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit)
library(party)
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit)
nrow(credit)
summary(credit)
colSums(is.na(credit))
table(credit$default)
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
table(predict(credit_ctree),train_data$default)
testpred <- predict(credit_ctree, newdata=test_data)
table(testpred, test_data$default)
library(gmodels)
g2 <- CrossTable(test_data$default, testpred)
x <- sum(g2$prop.tbl*diag(2))
if(x>=0.86) break
print(i)}
print(i) # 393
x # 0.86
i = 0
repeat{
set.seed(i)
i = i + 1
credit_shuffle = credit[sample(1000),]
train_num = 0.9 * 1000
train_data = credit_shuffle[1:train_num,]
test_data = credit_shuffle[(train_num +1):nrow(credit_shuffle),]
myformula = default ~.
credit_ctree = ctree(myformula, data = train_data)
test_pred = predict(credit_ctree, newdata = test_data)
gm = CrossTable(test_data$default, test_pred)
corr_ratio = sum(gm$prop.tbl*diag(2))
if (corr_ratio == 0.86)
break
print(i)
}
print(i)
corr_ratio
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
table(predict(credit_ctree),train_data$default)
testpred <- predict(credit_ctree, newdata=test_data)
table(testpred, test_data$default)
g_m <- CrossTable(test_data$default, testpred)
c_ratio <- sum(g_m$prop.tbl*diag(2))
if(c_ratio>=0.86) break
print(i)}
print(i) # 393
c_ratio # 0.86
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
testpred <- predict(credit_ctree, newdata=test_data)
g_m <- CrossTable(test_data$default, testpred)
c_ratio <- sum(g_m$prop.tbl*diag(2))
if(c_ratio>=0.86) break
print(i)}
print(i) # 393
c_ratio # 0.86
library(gmodels)
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit) #type 확인 필수
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
testpred <- predict(credit_ctree, newdata=test_data)
g_m <- CrossTable(test_data$default, testpred)
c_ratio <- sum(g_m$prop.tbl*diag(2))
if(c_ratio>=0.86) break
print(i)
}
print(i) #393
c_ratio #0.86
library(gmodels)
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit) #type 확인 필수
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
testpred <- predict(credit_ctree, newdata=test_data)
g_m <- CrossTable(test_data$default, testpred)
a <- sum(g_m$prop.tbl*diag(2))
if(a>=0.86) break
print(i)
}
print(i) #393
a #0.86
plot(credit_ctree, type='simple')
library(gmodels)
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit) #type 확인 필수
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
testpred <- predict(credit_ctree, newdata=test_data)
g_m <- CrossTable(test_data$default, testpred)
a <- sum(g_m$prop.tbl*diag(2))
if(a>=0.86) break
print(i)
}
print(i) #393
a #0.86
plot(credit_ctree, type='simple')
library(party)
library(gmodels)
credit <- read.csv("credit.csv", stringsAsFactors =TRUE)
str(credit) #type 확인 필수
i <- 1
repeat {
set.seed(i)
i <- i+1
ind <- sample(2, nrow(credit), replace = T, prob=c(0.9,0.1))
train_data <- credit[ind==1,]
test_data <- credit[ind==2,]
myformula <- default~.
credit_ctree <- ctree(myformula, data=train_data)
predict(credit_ctree)
testpred <- predict(credit_ctree, newdata=test_data)
g_m <- CrossTable(test_data$default, testpred)
a <- sum(g_m$prop.tbl*diag(2))
if(a>=0.86) break
print(i)
}
print(i) #393
a #0.86
plot(credit_ctree, type='simple')
